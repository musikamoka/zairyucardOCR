{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5tLbWySxSWbu",
        "outputId": "e16256bb-d8ab-4761-d4e4-b919969026ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=346d27510a36e5e09eb7297645f02e054f3b6785a009332cc157f632ba71ae02\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "#1モデルの指定 PyTorchバージョン\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSVWP_vRM2Ts",
        "outputId": "e1b95811-de3a-4762-debc-0706febb24e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5XrRi8w8SX6-",
        "outputId": "10c62cf5-b227-4c28-f9ac-ed106eb0e8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers==0.0.22 in /usr/local/lib/python3.11/dist-packages (0.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.22) (2.0.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.22) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.22) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.22) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->xformers==0.0.22) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->xformers==0.0.22) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#2モデルの指定xformersバージョン\n",
        "!pip install xformers==0.0.22\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bsntVadiEcF",
        "outputId": "37f002fd-6376-4121-9f84-60b3d5b535ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepseek-ai/deepseek-vl2.git\n",
            "  Cloning https://github.com/deepseek-ai/deepseek-vl2.git to /tmp/pip-req-build-j_5h1k8x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepseek-ai/deepseek-vl2.git /tmp/pip-req-build-j_5h1k8x\n",
            "  Resolved https://github.com/deepseek-ai/deepseek-vl2.git to commit ef9f91e2b6426536b83294c11742c27be66361b1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (2.0.1+cu118)\n",
            "Collecting transformers==4.38.2 (from deepseek_vl2==1.0.0)\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: timm>=0.9.16 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.0.16)\n",
            "Requirement already satisfied: xformers>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.0.22)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.2.0)\n",
            "Collecting attrdict (from deepseek_vl2==1.0.0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->deepseek_vl2==1.0.0)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (15.0.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->deepseek_vl2==1.0.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->deepseek_vl2==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->deepseek_vl2==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->deepseek_vl2==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->deepseek_vl2==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.16->deepseek_vl2==1.0.0) (11.2.1)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepseek_vl2\n",
            "  Building wheel for deepseek_vl2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepseek_vl2: filename=deepseek_vl2-1.0.0-py3-none-any.whl size=72458 sha256=2f5934c4fa73537905df9e8961fca742a83dd521421fa109287ccc7f22bdd88c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bdm8l9nc/wheels/a8/3b/ee/22272a2bf61c51044b87cfd55553724ec298ead3ad2f2dd4c7\n",
            "Successfully built deepseek_vl2\n",
            "Installing collected packages: attrdict, tokenizers, transformers, deepseek_vl2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrdict-2.0.1 deepseek_vl2-1.0.0 tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ],
      "source": [
        "#main 環境設置\n",
        "!pip install git+https://github.com/deepseek-ai/deepseek-vl2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zDYOWLsDPKJD",
        "outputId": "e7ce8471-8ffe-4c05-cd4e-d193505a783e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.38.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: deepseek_vl2, peft, sentence-transformers\n",
            "Name: transformers\n",
            "Version: 4.38.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: deepseek_vl2, peft, sentence-transformers\n",
            "Name: accelerate\n",
            "Version: 1.8.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: deepseek_vl2, peft\n",
            "Name: accelerate\n",
            "Version: 1.8.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: deepseek_vl2, peft\n",
            "Name: deepseek_vl2\n",
            "Version: 1.0.0\n",
            "Summary: DeepSeek-VL2\n",
            "Home-page: https://github.com/deepseek-ai/DeepSeek-VL2\n",
            "Author: DeepSeek-AI\n",
            "Author-email: \n",
            "License: MIT License\n",
            "\n",
            "Copyright (c) 2023 DeepSeek\n",
            "\n",
            "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "of this software and associated documentation files (the \"Software\"), to deal\n",
            "in the Software without restriction, including without limitation the rights\n",
            "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "copies of the Software, and to permit persons to whom the Software is\n",
            "furnished to do so, subject to the following conditions:\n",
            "\n",
            "The above copyright notice and this permission notice shall be included in all\n",
            "copies or substantial portions of the Software.\n",
            "\n",
            "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "SOFTWARE.\n",
            "\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, attrdict, einops, sentencepiece, timm, torch, transformers, xformers\n",
            "Required-by: \n",
            "Name: deepseek_vl2\n",
            "Version: 1.0.0\n",
            "Summary: DeepSeek-VL2\n",
            "Home-page: https://github.com/deepseek-ai/DeepSeek-VL2\n",
            "Author: DeepSeek-AI\n",
            "Author-email: \n",
            "License: MIT License\n",
            "\n",
            "Copyright (c) 2023 DeepSeek\n",
            "\n",
            "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "of this software and associated documentation files (the \"Software\"), to deal\n",
            "in the Software without restriction, including without limitation the rights\n",
            "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "copies of the Software, and to permit persons to whom the Software is\n",
            "furnished to do so, subject to the following conditions:\n",
            "\n",
            "The above copyright notice and this permission notice shall be included in all\n",
            "copies or substantial portions of the Software.\n",
            "\n",
            "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "SOFTWARE.\n",
            "\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, attrdict, einops, sentencepiece, timm, torch, transformers, xformers\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "#必要環境検査\n",
        "!pip show transformers || pip install -q transformers && pip show transformers\n",
        "!pip show accelerate || pip install -q accelerate && pip show accelerate\n",
        "!pip show deepseek-vl2 || pip install -q git+https://github.com/deepseek-ai/deepseek-vl2.git && pip show deepseek-vl2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpPcrJwZTe5r",
        "outputId": "5cfd9fd8-776a-4830-bdc5-9b6f985d52fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version is above 3.10, patching the collections module.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n",
            "<｜▁pad▁｜>:2\n",
            "Add image token = ['<image>'] to the tokenizer\n",
            "<image>:128815\n",
            "Add grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n",
            "<|ref|>:128816\n",
            "<|/ref|>:128817\n",
            "<|det|>:128818\n",
            "<|/det|>:128819\n",
            "<|grounding|>:128820\n",
            "Add chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n",
            "<|User|>:128821\n",
            "<|Assistant|>:128822\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OCRモデル初期化完了。以下を実行してください：\n",
            "- process_single()：1枚の画像を認識\n",
            "- process_batch()：複数画像を一括認識\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "import os, csv, re\n",
        "from deepseek_vl2.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
        "from deepseek_vl2.utils.io import load_pil_images\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# ✅ OCR モードはdeepseek desu\n",
        "# ------------------------------\n",
        "class OCRModel:\n",
        "    def __init__(self, model_path=\"deepseek-ai/deepseek-vl2-tiny\"):\n",
        "        self.processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
        "        self.tokenizer = self.processor.tokenizer\n",
        "        self.model = DeepseekVLV2ForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "        self.model.config.use_flash_attention = False\n",
        "        self.model = self.model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        conversation = [\n",
        "            {\n",
        "                \"role\": \"<|User|>\",\n",
        "                \"content\": \"\"\"<image>\\n\n",
        "                言語設定：日本語。\n",
        "                以下の項目だけ答えてください：\n",
        "                - 国籍（例：ベトナム、韓国、中国など）\n",
        "                - 氏名（氏名は原文の通り、たとえ英語でもカタカナに変換しないでください。）\n",
        "                - 性別（男 または 女）\n",
        "                - 生年月日\n",
        "                - 住居地（都道府県から）\n",
        "                - 在留資格（例：留学、家族滞在など）\n",
        "                - 在留カード番号（右上の番号は在留カード番号です）\n",
        "                - 在留期間(PERIOD OF STAY):X年X月 (XXXX年XX月XX日)\n",
        "                それ以外の説明や解説は不要です。\"\"\",\n",
        "                \"images\": [image_path],\n",
        "            },\n",
        "            {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "        ]\n",
        "\n",
        "        pil_images = load_pil_images(conversation)\n",
        "        inputs = self.processor(conversations=conversation, images=pil_images, force_batchify=True)\n",
        "        inputs = inputs.to(self.model.device)\n",
        "\n",
        "        inputs_dict = dict(inputs)\n",
        "\n",
        "        # ✅  float32　だけ\n",
        "        for k, v in inputs_dict.items():\n",
        "            if isinstance(v, torch.Tensor) and k in [\"pixel_values\", \"images\"]:\n",
        "                inputs_dict[k] = v.to(torch.float32)\n",
        "\n",
        "        inputs_embeds = self.model.prepare_inputs_embeds(**inputs_dict)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=inputs_dict.get(\"attention_mask\"),\n",
        "            pad_token_id=self.tokenizer.eos_token_id,\n",
        "            bos_token_id=self.tokenizer.bos_token_id,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            max_new_tokens=500,\n",
        "            do_sample=False,\n",
        "            use_cache=True,\n",
        "        )\n",
        "\n",
        "        return self.tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "\n",
        "# ------------------------------\n",
        "# ✅ 文字列\n",
        "# ------------------------------\n",
        "def extract_fields(text):\n",
        "    def extract_multiline_address(text):\n",
        "        match = re.search(r\"住居地[:：]?\\s*(.+)\", text)\n",
        "        return match.group(1).strip() if match else \"\"\n",
        "\n",
        "    def extract_stay_period(text):\n",
        "        pattern = r\"在留期間(?:\\(PERIOD OF STAY\\))?[:：]?\\s*(\\d+年(?:\\d+月)?)\\s*[（(](\\d{4}年\\d{1,2}月\\d{1,2}日)[）)]\"\n",
        "        match = re.search(pattern, text)\n",
        "        return (match.group(1), match.group(2)) if match else (\"\", \"\")\n",
        "\n",
        "    def extract_card_number(text):\n",
        "        match = re.search(r\"在留カード番号[:：]?\\s*([A-Z0-9]+)\", text)\n",
        "        return match.group(1) if match else \"\"\n",
        "\n",
        "    return {\n",
        "        \"国籍\": re.search(r\"国籍[:：]?\\s*([^\\s\\n]+)\", text).group(1) if re.search(r\"国籍[:：]?\\s*([^\\s\\n]+)\", text) else \"\",\n",
        "        \"氏名\": re.search(r\"氏名[:：]?\\s*(.+)\", text).group(1).strip() if re.search(r\"氏名[:：]?\\s*(.+)\", text) else \"\",\n",
        "        \"性別\": re.search(r\"性別[:：]?\\s*(男|女)\", text).group(1) if re.search(r\"性別[:：]?\\s*(男|女)\", text) else \"\",\n",
        "        \"生年月日\": re.search(r\"生年月日[:：]?\\s*(\\d{4}年\\d{1,2}月\\d{1,2}日)\", text).group(1) if re.search(r\"生年月日[:：]?\\s*(\\d{4}年\\d{1,2}月\\d{1,2}日)\", text) else \"\",\n",
        "        \"住居地\": extract_multiline_address(text),\n",
        "        \"在留資格\": re.search(r\"在留資格[:：]?\\s*(\\S+)\", text).group(1) if re.search(r\"在留資格[:：]?\\s*(\\S+)\", text) else \"\",\n",
        "        \"在留カード番号\": extract_card_number(text),\n",
        "        \"在留期間_期間\": extract_stay_period(text)[0],\n",
        "        \"在留期間_満了日\": extract_stay_period(text)[1],\n",
        "    }\n",
        "\n",
        "# ------------------------------\n",
        "# ✅ 保存 CSV\n",
        "# ------------------------------\n",
        "def save_to_csv(data_list, path):\n",
        "    keys = [\"学籍番号\"] + [k for k in data_list[0].keys() if k != \"学籍番号\"]\n",
        "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=keys)\n",
        "        writer.writeheader()\n",
        "        for row in data_list:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# ------------------------------\n",
        "# ✅ 一つファイル\n",
        "# ------------------------------\n",
        "# def process_single():\n",
        "#     uploaded = files.upload()\n",
        "#     for filename in uploaded.keys():\n",
        "#         result = ocr.predict(filename)\n",
        "#         fields = extract_fields(result)\n",
        "#         fields[\"学籍番号\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "#         save_to_csv([fields], \"result_single.csv\")\n",
        "#         files.download(\"result_single.csv\")\n",
        "# def process_single():\n",
        "#     uploaded = files.upload()\n",
        "#     for filename in uploaded.keys():\n",
        "#         result = ocr.predict(filename)\n",
        "#         fields = extract_fields(result)\n",
        "#         fields[\"学籍番号\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "#         # ✅ Step 1: 显示OCR提取结果\n",
        "#         print(\"\\n📄 抽出された項目:\")\n",
        "#         for key, value in fields.items():\n",
        "#             print(f\"{key}: {value}\")\n",
        "\n",
        "#         # ✅ Step 2: 创建确认按钮\n",
        "#         confirm_button = widgets.ToggleButtons(\n",
        "#             options=[\"はい、CSV保存する\", \"いいえ、保存しない\"],\n",
        "#             description=\"保存しますか？\",\n",
        "#             disabled=False,\n",
        "#             button_style='',\n",
        "#             tooltips=[\"保存する\", \"保存しない\"],\n",
        "#         )\n",
        "#         display(confirm_button)\n",
        "\n",
        "#         # ✅ Step 3: 等待用户确认\n",
        "#         def on_confirm_change(change):\n",
        "#             if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "#                 if change[\"new\"] == \"はい、CSV保存する\":\n",
        "#                     save_to_csv([fields], \"result_single.csv\")\n",
        "#                     files.download(\"result_single.csv\")\n",
        "#                     print(\"✅ 保存しました: result_single.csv\")\n",
        "#                 else:\n",
        "#                     print(\"❌ 保存しませんでした。\")\n",
        "#                 confirm_button.close()\n",
        "\n",
        "#         confirm_button.observe(on_confirm_change)\n",
        "#         break\n",
        "def process_single():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        result = ocr.predict(filename)\n",
        "\n",
        "        # ✅ Step 1: 显示 OCR 原始全文\n",
        "        print(\"\\n📝 OCR 抽出された全文:\")\n",
        "        print(result)\n",
        "\n",
        "        # ✅ Step 2: 字段抽出\n",
        "        fields = extract_fields(result)\n",
        "        fields[\"学籍番号\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "        # ✅ Step 3: 显示字段结果\n",
        "        print(\"\\n📄 抽出された項目:\")\n",
        "        for key, value in fields.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "        # ✅ Step 4: 创建确认按钮\n",
        "        confirm_button = widgets.ToggleButtons(\n",
        "            options=[\"はい、CSV保存する\", \"いいえ、保存しない\"],\n",
        "            description=\"保存しますか？\",\n",
        "            disabled=False,\n",
        "            button_style='',\n",
        "            tooltips=[\"保存する\", \"保存しない\"],\n",
        "        )\n",
        "        display(confirm_button)\n",
        "\n",
        "        # ✅ Step 5: 等待用户确认是否保存\n",
        "        def on_confirm_change(change):\n",
        "            if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "                if change[\"new\"] == \"はい、CSV保存する\":\n",
        "                    save_to_csv([fields], \"result_single.csv\")\n",
        "                    files.download(\"result_single.csv\")\n",
        "                    print(\"✅ 保存しました: result_single.csv\")\n",
        "                else:\n",
        "                    print(\"❌ 保存しませんでした。\")\n",
        "                confirm_button.close()\n",
        "\n",
        "        confirm_button.observe(on_confirm_change)\n",
        "        break  # 只处理1张图像\n",
        "# ------------------------------\n",
        "# ✅ 多数ファイル\n",
        "# ------------------------------\n",
        "def process_batch():\n",
        "    uploaded = files.upload()\n",
        "    results = []\n",
        "    for filename in uploaded.keys():\n",
        "        result = ocr.predict(filename)\n",
        "        fields = extract_fields(result)\n",
        "        fields[\"学籍番号\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "        results.append(fields)\n",
        "    save_to_csv(results, \"result_batch.csv\")\n",
        "    files.download(\"result_batch.csv\")\n",
        "\n",
        "# ------------------------------\n",
        "# ✅ OCRモデル初期化\n",
        "# ------------------------------\n",
        "ocr = OCRModel(\"deepseek-ai/deepseek-vl2-tiny\")\n",
        "print(\"✅ OCRモデル初期化完了。以下を実行してください：\")\n",
        "print(\"- process_single()：1枚の画像を認識\")\n",
        "print(\"- process_batch()：複数画像を一括認識\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "a2eb5318d3da44508fcd3fab08d6bf9b",
            "38c55aacb05a472cb65f3c1136e7d11f",
            "034f4b878f0740ea9b7d7adf5364f2cc"
          ]
        },
        "id": "wITQLIeRVh70",
        "outputId": "c5d8a287-2883-4ea7-f0c1-7e4a6b7c5693"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-335f63b8-02af-4998-8c10-dcc6255c1c72\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-335f63b8-02af-4998-8c10-dcc6255c1c72\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 22TE429.png to 22TE429 (13).png\n",
            "\n",
            "📝 OCR 抽出された全文:\n",
            "国籍：ベトナム\n",
            "氏名：TO THIEN LONG\n",
            "性別：男\n",
            "生年月日：2月5日\n",
            "住居地：東京都台東区上野1丁目\n",
            "在留資格：留学\n",
            "在留カード番号：SA68\n",
            "在留期間：1年8月（2026年06月01日）\n",
            "在留期間更新許可：2024年10月01日\n",
            " expiration date: Y M D\n",
            "\n",
            "📄 抽出された項目:\n",
            "国籍: ベトナム\n",
            "氏名: TO THIEN LONG\n",
            "性別: 男\n",
            "生年月日: \n",
            "住居地: 東京都台東区上野1丁目\n",
            "在留資格: 留学\n",
            "在留カード番号: SA68\n",
            "在留期間_期間: 1年8月\n",
            "在留期間_満了日: 2026年06月01日\n",
            "学籍番号: 22TE429 (13)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='保存しますか？', options=('はい、CSV保存する', 'いいえ、保存しない'), tooltips=('保存する', '保存しない'), value='は…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2eb5318d3da44508fcd3fab08d6bf9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ 保存しませんでした。\n"
          ]
        }
      ],
      "source": [
        "#単ファイルOCR\n",
        "process_single()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "collapsed": true,
        "id": "5hXhH9GDVib5",
        "outputId": "52387f31-1f91-4c89-e9e6-76df020badc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e4ac433-264f-4062-8997-254e28a47464\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e4ac433-264f-4062-8997-254e28a47464\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 22TE429.png to 22TE429 (15).png\n",
            "Saving 22TE487.jpg to 22TE487 (5).jpg\n",
            "Saving 23TE465.png to 23TE465 (1).png\n",
            "Saving 番号不明.jpg to 番号不明 (2).jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c50a4998-b746-4c31-bd33-833526098e88\", \"result_batch.csv\", 571)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#多数ファイルOCR\n",
        "process_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MJvglRddjo1"
      },
      "outputs": [],
      "source": [
        "#モード再開\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOJyROmq3vzA"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMAPmNkTT5lza0rp9FMTXYn"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2eb5318d3da44508fcd3fab08d6bf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "はい、CSV保存する",
              "いいえ、保存しない"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "保存しますか？",
            "description_tooltip": null,
            "disabled": false,
            "icons": [],
            "index": 1,
            "layout": "IPY_MODEL_38c55aacb05a472cb65f3c1136e7d11f",
            "style": "IPY_MODEL_034f4b878f0740ea9b7d7adf5364f2cc",
            "tooltips": [
              "保存する",
              "保存しない"
            ]
          }
        },
        "38c55aacb05a472cb65f3c1136e7d11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034f4b878f0740ea9b7d7adf5364f2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}