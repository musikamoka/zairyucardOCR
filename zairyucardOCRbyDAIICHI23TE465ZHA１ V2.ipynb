{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5tLbWySxSWbu",
        "outputId": "e16256bb-d8ab-4761-d4e4-b919969026ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=346d27510a36e5e09eb7297645f02e054f3b6785a009332cc157f632ba71ae02\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "#1ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSVWP_vRM2Ts",
        "outputId": "e1b95811-de3a-4762-debc-0706febb24e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5XrRi8w8SX6-",
        "outputId": "10c62cf5-b227-4c28-f9ac-ed106eb0e8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers==0.0.22 in /usr/local/lib/python3.11/dist-packages (0.0.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.22) (2.0.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.22) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->xformers==0.0.22) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.22) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->xformers==0.0.22) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->xformers==0.0.22) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->xformers==0.0.22) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#2ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®šxformersãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
        "!pip install xformers==0.0.22\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bsntVadiEcF",
        "outputId": "37f002fd-6376-4121-9f84-60b3d5b535ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepseek-ai/deepseek-vl2.git\n",
            "  Cloning https://github.com/deepseek-ai/deepseek-vl2.git to /tmp/pip-req-build-j_5h1k8x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepseek-ai/deepseek-vl2.git /tmp/pip-req-build-j_5h1k8x\n",
            "  Resolved https://github.com/deepseek-ai/deepseek-vl2.git to commit ef9f91e2b6426536b83294c11742c27be66361b1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (2.0.1+cu118)\n",
            "Collecting transformers==4.38.2 (from deepseek_vl2==1.0.0)\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: timm>=0.9.16 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.0.16)\n",
            "Requirement already satisfied: xformers>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.0.22)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (1.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.2.0)\n",
            "Collecting attrdict (from deepseek_vl2==1.0.0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepseek_vl2==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->deepseek_vl2==1.0.0)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (15.0.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm>=0.9.16->deepseek_vl2==1.0.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->deepseek_vl2==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->deepseek_vl2==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->deepseek_vl2==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->deepseek_vl2==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm>=0.9.16->deepseek_vl2==1.0.0) (11.2.1)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepseek_vl2\n",
            "  Building wheel for deepseek_vl2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepseek_vl2: filename=deepseek_vl2-1.0.0-py3-none-any.whl size=72458 sha256=2f5934c4fa73537905df9e8961fca742a83dd521421fa109287ccc7f22bdd88c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bdm8l9nc/wheels/a8/3b/ee/22272a2bf61c51044b87cfd55553724ec298ead3ad2f2dd4c7\n",
            "Successfully built deepseek_vl2\n",
            "Installing collected packages: attrdict, tokenizers, transformers, deepseek_vl2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrdict-2.0.1 deepseek_vl2-1.0.0 tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ],
      "source": [
        "#main ç’°å¢ƒè¨­ç½®\n",
        "!pip install git+https://github.com/deepseek-ai/deepseek-vl2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zDYOWLsDPKJD",
        "outputId": "e7ce8471-8ffe-4c05-cd4e-d193505a783e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.38.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: deepseek_vl2, peft, sentence-transformers\n",
            "Name: transformers\n",
            "Version: 4.38.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: deepseek_vl2, peft, sentence-transformers\n",
            "Name: accelerate\n",
            "Version: 1.8.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: deepseek_vl2, peft\n",
            "Name: accelerate\n",
            "Version: 1.8.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: deepseek_vl2, peft\n",
            "Name: deepseek_vl2\n",
            "Version: 1.0.0\n",
            "Summary: DeepSeek-VL2\n",
            "Home-page: https://github.com/deepseek-ai/DeepSeek-VL2\n",
            "Author: DeepSeek-AI\n",
            "Author-email: \n",
            "License: MIT License\n",
            "\n",
            "Copyright (c) 2023 DeepSeek\n",
            "\n",
            "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "of this software and associated documentation files (the \"Software\"), to deal\n",
            "in the Software without restriction, including without limitation the rights\n",
            "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "copies of the Software, and to permit persons to whom the Software is\n",
            "furnished to do so, subject to the following conditions:\n",
            "\n",
            "The above copyright notice and this permission notice shall be included in all\n",
            "copies or substantial portions of the Software.\n",
            "\n",
            "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "SOFTWARE.\n",
            "\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, attrdict, einops, sentencepiece, timm, torch, transformers, xformers\n",
            "Required-by: \n",
            "Name: deepseek_vl2\n",
            "Version: 1.0.0\n",
            "Summary: DeepSeek-VL2\n",
            "Home-page: https://github.com/deepseek-ai/DeepSeek-VL2\n",
            "Author: DeepSeek-AI\n",
            "Author-email: \n",
            "License: MIT License\n",
            "\n",
            "Copyright (c) 2023 DeepSeek\n",
            "\n",
            "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "of this software and associated documentation files (the \"Software\"), to deal\n",
            "in the Software without restriction, including without limitation the rights\n",
            "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "copies of the Software, and to permit persons to whom the Software is\n",
            "furnished to do so, subject to the following conditions:\n",
            "\n",
            "The above copyright notice and this permission notice shall be included in all\n",
            "copies or substantial portions of the Software.\n",
            "\n",
            "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "SOFTWARE.\n",
            "\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, attrdict, einops, sentencepiece, timm, torch, transformers, xformers\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "#å¿…è¦ç’°å¢ƒæ¤œæŸ»\n",
        "!pip show transformers || pip install -q transformers && pip show transformers\n",
        "!pip show accelerate || pip install -q accelerate && pip show accelerate\n",
        "!pip show deepseek-vl2 || pip install -q git+https://github.com/deepseek-ai/deepseek-vl2.git && pip show deepseek-vl2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpPcrJwZTe5r",
        "outputId": "5cfd9fd8-776a-4830-bdc5-9b6f985d52fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version is above 3.10, patching the collections module.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add pad token = ['<ï½œâ–padâ–ï½œ>'] to the tokenizer\n",
            "<ï½œâ–padâ–ï½œ>:2\n",
            "Add image token = ['<image>'] to the tokenizer\n",
            "<image>:128815\n",
            "Add grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n",
            "<|ref|>:128816\n",
            "<|/ref|>:128817\n",
            "<|det|>:128818\n",
            "<|/det|>:128819\n",
            "<|grounding|>:128820\n",
            "Add chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n",
            "<|User|>:128821\n",
            "<|Assistant|>:128822\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†ã€‚ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\n",
            "- process_single()ï¼š1æšã®ç”»åƒã‚’èªè­˜\n",
            "- process_batch()ï¼šè¤‡æ•°ç”»åƒã‚’ä¸€æ‹¬èªè­˜\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from google.colab import files\n",
        "import os, csv, re\n",
        "from deepseek_vl2.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
        "from deepseek_vl2.utils.io import load_pil_images\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# âœ… OCR ãƒ¢ãƒ¼ãƒ‰ã¯deepseek desu\n",
        "# ------------------------------\n",
        "class OCRModel:\n",
        "    def __init__(self, model_path=\"deepseek-ai/deepseek-vl2-tiny\"):\n",
        "        self.processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
        "        self.tokenizer = self.processor.tokenizer\n",
        "        self.model = DeepseekVLV2ForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "        self.model.config.use_flash_attention = False\n",
        "        self.model = self.model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        conversation = [\n",
        "            {\n",
        "                \"role\": \"<|User|>\",\n",
        "                \"content\": \"\"\"<image>\\n\n",
        "                è¨€èªè¨­å®šï¼šæ—¥æœ¬èªã€‚\n",
        "                ä»¥ä¸‹ã®é …ç›®ã ã‘ç­”ãˆã¦ãã ã•ã„ï¼š\n",
        "                - å›½ç±ï¼ˆä¾‹ï¼šãƒ™ãƒˆãƒŠãƒ ã€éŸ“å›½ã€ä¸­å›½ãªã©ï¼‰\n",
        "                - æ°åï¼ˆæ°åã¯åŸæ–‡ã®é€šã‚Šã€ãŸã¨ãˆè‹±èªã§ã‚‚ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã—ãªã„ã§ãã ã•ã„ã€‚ï¼‰\n",
        "                - æ€§åˆ¥ï¼ˆç”· ã¾ãŸã¯ å¥³ï¼‰\n",
        "                - ç”Ÿå¹´æœˆæ—¥\n",
        "                - ä½å±…åœ°ï¼ˆéƒ½é“åºœçœŒã‹ã‚‰ï¼‰\n",
        "                - åœ¨ç•™è³‡æ ¼ï¼ˆä¾‹ï¼šç•™å­¦ã€å®¶æ—æ»åœ¨ãªã©ï¼‰\n",
        "                - åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·ï¼ˆå³ä¸Šã®ç•ªå·ã¯åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·ã§ã™ï¼‰\n",
        "                - åœ¨ç•™æœŸé–“(PERIOD OF STAY):Xå¹´Xæœˆ (XXXXå¹´XXæœˆXXæ—¥)\n",
        "                ãã‚Œä»¥å¤–ã®èª¬æ˜ã‚„è§£èª¬ã¯ä¸è¦ã§ã™ã€‚\"\"\",\n",
        "                \"images\": [image_path],\n",
        "            },\n",
        "            {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "        ]\n",
        "\n",
        "        pil_images = load_pil_images(conversation)\n",
        "        inputs = self.processor(conversations=conversation, images=pil_images, force_batchify=True)\n",
        "        inputs = inputs.to(self.model.device)\n",
        "\n",
        "        inputs_dict = dict(inputs)\n",
        "\n",
        "        # âœ…  float32ã€€ã ã‘\n",
        "        for k, v in inputs_dict.items():\n",
        "            if isinstance(v, torch.Tensor) and k in [\"pixel_values\", \"images\"]:\n",
        "                inputs_dict[k] = v.to(torch.float32)\n",
        "\n",
        "        inputs_embeds = self.model.prepare_inputs_embeds(**inputs_dict)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=inputs_dict.get(\"attention_mask\"),\n",
        "            pad_token_id=self.tokenizer.eos_token_id,\n",
        "            bos_token_id=self.tokenizer.bos_token_id,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            max_new_tokens=500,\n",
        "            do_sample=False,\n",
        "            use_cache=True,\n",
        "        )\n",
        "\n",
        "        return self.tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "\n",
        "# ------------------------------\n",
        "# âœ… æ–‡å­—åˆ—\n",
        "# ------------------------------\n",
        "def extract_fields(text):\n",
        "    def extract_multiline_address(text):\n",
        "        match = re.search(r\"ä½å±…åœ°[:ï¼š]?\\s*(.+)\", text)\n",
        "        return match.group(1).strip() if match else \"\"\n",
        "\n",
        "    def extract_stay_period(text):\n",
        "        pattern = r\"åœ¨ç•™æœŸé–“(?:\\(PERIOD OF STAY\\))?[:ï¼š]?\\s*(\\d+å¹´(?:\\d+æœˆ)?)\\s*[ï¼ˆ(](\\d{4}å¹´\\d{1,2}æœˆ\\d{1,2}æ—¥)[ï¼‰)]\"\n",
        "        match = re.search(pattern, text)\n",
        "        return (match.group(1), match.group(2)) if match else (\"\", \"\")\n",
        "\n",
        "    def extract_card_number(text):\n",
        "        match = re.search(r\"åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·[:ï¼š]?\\s*([A-Z0-9]+)\", text)\n",
        "        return match.group(1) if match else \"\"\n",
        "\n",
        "    return {\n",
        "        \"å›½ç±\": re.search(r\"å›½ç±[:ï¼š]?\\s*([^\\s\\n]+)\", text).group(1) if re.search(r\"å›½ç±[:ï¼š]?\\s*([^\\s\\n]+)\", text) else \"\",\n",
        "        \"æ°å\": re.search(r\"æ°å[:ï¼š]?\\s*(.+)\", text).group(1).strip() if re.search(r\"æ°å[:ï¼š]?\\s*(.+)\", text) else \"\",\n",
        "        \"æ€§åˆ¥\": re.search(r\"æ€§åˆ¥[:ï¼š]?\\s*(ç”·|å¥³)\", text).group(1) if re.search(r\"æ€§åˆ¥[:ï¼š]?\\s*(ç”·|å¥³)\", text) else \"\",\n",
        "        \"ç”Ÿå¹´æœˆæ—¥\": re.search(r\"ç”Ÿå¹´æœˆæ—¥[:ï¼š]?\\s*(\\d{4}å¹´\\d{1,2}æœˆ\\d{1,2}æ—¥)\", text).group(1) if re.search(r\"ç”Ÿå¹´æœˆæ—¥[:ï¼š]?\\s*(\\d{4}å¹´\\d{1,2}æœˆ\\d{1,2}æ—¥)\", text) else \"\",\n",
        "        \"ä½å±…åœ°\": extract_multiline_address(text),\n",
        "        \"åœ¨ç•™è³‡æ ¼\": re.search(r\"åœ¨ç•™è³‡æ ¼[:ï¼š]?\\s*(\\S+)\", text).group(1) if re.search(r\"åœ¨ç•™è³‡æ ¼[:ï¼š]?\\s*(\\S+)\", text) else \"\",\n",
        "        \"åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·\": extract_card_number(text),\n",
        "        \"åœ¨ç•™æœŸé–“_æœŸé–“\": extract_stay_period(text)[0],\n",
        "        \"åœ¨ç•™æœŸé–“_æº€äº†æ—¥\": extract_stay_period(text)[1],\n",
        "    }\n",
        "\n",
        "# ------------------------------\n",
        "# âœ… ä¿å­˜ CSV\n",
        "# ------------------------------\n",
        "def save_to_csv(data_list, path):\n",
        "    keys = [\"å­¦ç±ç•ªå·\"] + [k for k in data_list[0].keys() if k != \"å­¦ç±ç•ªå·\"]\n",
        "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=keys)\n",
        "        writer.writeheader()\n",
        "        for row in data_list:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# ------------------------------\n",
        "# âœ… ä¸€ã¤ãƒ•ã‚¡ã‚¤ãƒ«\n",
        "# ------------------------------\n",
        "# def process_single():\n",
        "#     uploaded = files.upload()\n",
        "#     for filename in uploaded.keys():\n",
        "#         result = ocr.predict(filename)\n",
        "#         fields = extract_fields(result)\n",
        "#         fields[\"å­¦ç±ç•ªå·\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "#         save_to_csv([fields], \"result_single.csv\")\n",
        "#         files.download(\"result_single.csv\")\n",
        "# def process_single():\n",
        "#     uploaded = files.upload()\n",
        "#     for filename in uploaded.keys():\n",
        "#         result = ocr.predict(filename)\n",
        "#         fields = extract_fields(result)\n",
        "#         fields[\"å­¦ç±ç•ªå·\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "#         # âœ… Step 1: æ˜¾ç¤ºOCRæå–ç»“æœ\n",
        "#         print(\"\\nğŸ“„ æŠ½å‡ºã•ã‚ŒãŸé …ç›®:\")\n",
        "#         for key, value in fields.items():\n",
        "#             print(f\"{key}: {value}\")\n",
        "\n",
        "#         # âœ… Step 2: åˆ›å»ºç¡®è®¤æŒ‰é’®\n",
        "#         confirm_button = widgets.ToggleButtons(\n",
        "#             options=[\"ã¯ã„ã€CSVä¿å­˜ã™ã‚‹\", \"ã„ã„ãˆã€ä¿å­˜ã—ãªã„\"],\n",
        "#             description=\"ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ\",\n",
        "#             disabled=False,\n",
        "#             button_style='',\n",
        "#             tooltips=[\"ä¿å­˜ã™ã‚‹\", \"ä¿å­˜ã—ãªã„\"],\n",
        "#         )\n",
        "#         display(confirm_button)\n",
        "\n",
        "#         # âœ… Step 3: ç­‰å¾…ç”¨æˆ·ç¡®è®¤\n",
        "#         def on_confirm_change(change):\n",
        "#             if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "#                 if change[\"new\"] == \"ã¯ã„ã€CSVä¿å­˜ã™ã‚‹\":\n",
        "#                     save_to_csv([fields], \"result_single.csv\")\n",
        "#                     files.download(\"result_single.csv\")\n",
        "#                     print(\"âœ… ä¿å­˜ã—ã¾ã—ãŸ: result_single.csv\")\n",
        "#                 else:\n",
        "#                     print(\"âŒ ä¿å­˜ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "#                 confirm_button.close()\n",
        "\n",
        "#         confirm_button.observe(on_confirm_change)\n",
        "#         break\n",
        "def process_single():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        result = ocr.predict(filename)\n",
        "\n",
        "        # âœ… Step 1: æ˜¾ç¤º OCR åŸå§‹å…¨æ–‡\n",
        "        print(\"\\nğŸ“ OCR æŠ½å‡ºã•ã‚ŒãŸå…¨æ–‡:\")\n",
        "        print(result)\n",
        "\n",
        "        # âœ… Step 2: å­—æ®µæŠ½å‡º\n",
        "        fields = extract_fields(result)\n",
        "        fields[\"å­¦ç±ç•ªå·\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "\n",
        "        # âœ… Step 3: æ˜¾ç¤ºå­—æ®µç»“æœ\n",
        "        print(\"\\nğŸ“„ æŠ½å‡ºã•ã‚ŒãŸé …ç›®:\")\n",
        "        for key, value in fields.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "        # âœ… Step 4: åˆ›å»ºç¡®è®¤æŒ‰é’®\n",
        "        confirm_button = widgets.ToggleButtons(\n",
        "            options=[\"ã¯ã„ã€CSVä¿å­˜ã™ã‚‹\", \"ã„ã„ãˆã€ä¿å­˜ã—ãªã„\"],\n",
        "            description=\"ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ\",\n",
        "            disabled=False,\n",
        "            button_style='',\n",
        "            tooltips=[\"ä¿å­˜ã™ã‚‹\", \"ä¿å­˜ã—ãªã„\"],\n",
        "        )\n",
        "        display(confirm_button)\n",
        "\n",
        "        # âœ… Step 5: ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ˜¯å¦ä¿å­˜\n",
        "        def on_confirm_change(change):\n",
        "            if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
        "                if change[\"new\"] == \"ã¯ã„ã€CSVä¿å­˜ã™ã‚‹\":\n",
        "                    save_to_csv([fields], \"result_single.csv\")\n",
        "                    files.download(\"result_single.csv\")\n",
        "                    print(\"âœ… ä¿å­˜ã—ã¾ã—ãŸ: result_single.csv\")\n",
        "                else:\n",
        "                    print(\"âŒ ä¿å­˜ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "                confirm_button.close()\n",
        "\n",
        "        confirm_button.observe(on_confirm_change)\n",
        "        break  # åªå¤„ç†1å¼ å›¾åƒ\n",
        "# ------------------------------\n",
        "# âœ… å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«\n",
        "# ------------------------------\n",
        "def process_batch():\n",
        "    uploaded = files.upload()\n",
        "    results = []\n",
        "    for filename in uploaded.keys():\n",
        "        result = ocr.predict(filename)\n",
        "        fields = extract_fields(result)\n",
        "        fields[\"å­¦ç±ç•ªå·\"] = os.path.splitext(os.path.basename(filename))[0]\n",
        "        results.append(fields)\n",
        "    save_to_csv(results, \"result_batch.csv\")\n",
        "    files.download(\"result_batch.csv\")\n",
        "\n",
        "# ------------------------------\n",
        "# âœ… OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–\n",
        "# ------------------------------\n",
        "ocr = OCRModel(\"deepseek-ai/deepseek-vl2-tiny\")\n",
        "print(\"âœ… OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†ã€‚ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š\")\n",
        "print(\"- process_single()ï¼š1æšã®ç”»åƒã‚’èªè­˜\")\n",
        "print(\"- process_batch()ï¼šè¤‡æ•°ç”»åƒã‚’ä¸€æ‹¬èªè­˜\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "a2eb5318d3da44508fcd3fab08d6bf9b",
            "38c55aacb05a472cb65f3c1136e7d11f",
            "034f4b878f0740ea9b7d7adf5364f2cc"
          ]
        },
        "id": "wITQLIeRVh70",
        "outputId": "c5d8a287-2883-4ea7-f0c1-7e4a6b7c5693"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-335f63b8-02af-4998-8c10-dcc6255c1c72\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-335f63b8-02af-4998-8c10-dcc6255c1c72\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 22TE429.png to 22TE429 (13).png\n",
            "\n",
            "ğŸ“ OCR æŠ½å‡ºã•ã‚ŒãŸå…¨æ–‡:\n",
            "å›½ç±ï¼šãƒ™ãƒˆãƒŠãƒ \n",
            "æ°åï¼šTO THIEN LONG\n",
            "æ€§åˆ¥ï¼šç”·\n",
            "ç”Ÿå¹´æœˆæ—¥ï¼š2æœˆ5æ—¥\n",
            "ä½å±…åœ°ï¼šæ±äº¬éƒ½å°æ±åŒºä¸Šé‡1ä¸ç›®\n",
            "åœ¨ç•™è³‡æ ¼ï¼šç•™å­¦\n",
            "åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·ï¼šSA68\n",
            "åœ¨ç•™æœŸé–“ï¼š1å¹´8æœˆï¼ˆ2026å¹´06æœˆ01æ—¥ï¼‰\n",
            "åœ¨ç•™æœŸé–“æ›´æ–°è¨±å¯ï¼š2024å¹´10æœˆ01æ—¥\n",
            " expiration date: Y M D\n",
            "\n",
            "ğŸ“„ æŠ½å‡ºã•ã‚ŒãŸé …ç›®:\n",
            "å›½ç±: ãƒ™ãƒˆãƒŠãƒ \n",
            "æ°å: TO THIEN LONG\n",
            "æ€§åˆ¥: ç”·\n",
            "ç”Ÿå¹´æœˆæ—¥: \n",
            "ä½å±…åœ°: æ±äº¬éƒ½å°æ±åŒºä¸Šé‡1ä¸ç›®\n",
            "åœ¨ç•™è³‡æ ¼: ç•™å­¦\n",
            "åœ¨ç•™ã‚«ãƒ¼ãƒ‰ç•ªå·: SA68\n",
            "åœ¨ç•™æœŸé–“_æœŸé–“: 1å¹´8æœˆ\n",
            "åœ¨ç•™æœŸé–“_æº€äº†æ—¥: 2026å¹´06æœˆ01æ—¥\n",
            "å­¦ç±ç•ªå·: 22TE429 (13)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ', options=('ã¯ã„ã€CSVä¿å­˜ã™ã‚‹', 'ã„ã„ãˆã€ä¿å­˜ã—ãªã„'), tooltips=('ä¿å­˜ã™ã‚‹', 'ä¿å­˜ã—ãªã„'), value='ã¯â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2eb5318d3da44508fcd3fab08d6bf9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ä¿å­˜ã—ã¾ã›ã‚“ã§ã—ãŸã€‚\n"
          ]
        }
      ],
      "source": [
        "#å˜ãƒ•ã‚¡ã‚¤ãƒ«OCR\n",
        "process_single()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "collapsed": true,
        "id": "5hXhH9GDVib5",
        "outputId": "52387f31-1f91-4c89-e9e6-76df020badc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e4ac433-264f-4062-8997-254e28a47464\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e4ac433-264f-4062-8997-254e28a47464\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 22TE429.png to 22TE429 (15).png\n",
            "Saving 22TE487.jpg to 22TE487 (5).jpg\n",
            "Saving 23TE465.png to 23TE465 (1).png\n",
            "Saving ç•ªå·ä¸æ˜.jpg to ç•ªå·ä¸æ˜ (2).jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c50a4998-b746-4c31-bd33-833526098e88\", \"result_batch.csv\", 571)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#å¤šæ•°ãƒ•ã‚¡ã‚¤ãƒ«OCR\n",
        "process_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MJvglRddjo1"
      },
      "outputs": [],
      "source": [
        "#ãƒ¢ãƒ¼ãƒ‰å†é–‹\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOJyROmq3vzA"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMAPmNkTT5lza0rp9FMTXYn"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2eb5318d3da44508fcd3fab08d6bf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "ã¯ã„ã€CSVä¿å­˜ã™ã‚‹",
              "ã„ã„ãˆã€ä¿å­˜ã—ãªã„"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ",
            "description_tooltip": null,
            "disabled": false,
            "icons": [],
            "index": 1,
            "layout": "IPY_MODEL_38c55aacb05a472cb65f3c1136e7d11f",
            "style": "IPY_MODEL_034f4b878f0740ea9b7d7adf5364f2cc",
            "tooltips": [
              "ä¿å­˜ã™ã‚‹",
              "ä¿å­˜ã—ãªã„"
            ]
          }
        },
        "38c55aacb05a472cb65f3c1136e7d11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034f4b878f0740ea9b7d7adf5364f2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}